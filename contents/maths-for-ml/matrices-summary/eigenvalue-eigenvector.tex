\subsection{Eigenvalues ($\lambda$) \& Eigenvectors}

\begin{enumerate}
    \item Eigen is a German word meaning “characteristic”, “self”, or “own”.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item \textbf{Definition}: Let $\bm{A} \in \mathbb{R}^{n\times n}$ be a square matrix. 
    Then $\lambda \in \mathbb{R}$ is an eigenvalue of $\bm{A}$ and $\bm{x} \in \mathbb{R}^n\backslash\dCurlyBrac{0}$ is the corresponding eigenvector of $\bm{A}$ if
    $\bm{Ax} = \lambda \bm{x}$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item $\bm{Ax} = \lambda \bm{x}$ is called eigenvalue equation.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item it is often a convention that eigenvalues are sorted in descending order, so that the largest eigenvalue and associated eigenvector are called the \textbf{first eigenvalue} and its associated eigenvector, and the second largest called the \textbf{second eigenvalue} and its associated eigenvector, and so on.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item The following statements are equivalent:
    \begin{enumerate}
        \item $\lambda$ is an eigenvalue of $\bm{A} \in \mathbb{R}^{n\times n}$
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item There exists an $\bm{x} \in \mathbb{R}^n\backslash\dCurlyBrac{0}$ with $\bm{Ax} = \lambda \bm{x}$, or equivalently, $(\bm{A} - \lambda \bm{I}_n)\bm{x} = 0$ can be solved non-trivially, i.e., $\bm{x} \neq 0$.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $rk(\bm{A} - \lambda \bm{I}_n) < n$
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $\det(\bm{A} - \lambda \bm{I}_n) = 0$
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \end{enumerate}

    \item \textbf{Non-uniqueness of eigenvectors}: If $\bm{x}$ is an eigenvector of $\bm{A}$ associated with eigenvalue $\lambda$, then for any $c \in \mathbb{R}\backslash \dCurlyBrac{0}$ it holds that $c\bm{x}$ is an eigenvector of $\bm{A}$ with the same eigenvalue since $\bm{A}(c\bm{x}) = c\bm{Ax} = c\lambda\bm{x} = \lambda(c\bm{x})$. All vectors that are collinear to $\bm{x}$ are also eigenvectors of $\bm{A}$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item \textbf{Theorem}: $\lambda  \in \mathbb{R}$ is an eigenvalue of $\bm{A} \in \mathbb{R}^{n\times n}$ if and only if $\lambda$  is a root of the characteristic polynomial $p_{\bm{A}}(\lambda )$ of $\bm{A}$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item \textbf{Definition}: Let a square matrix $\bm{A}$ have an eigenvalue $\lambda_i$ . 
    The \textbf{algebraic  multiplicity} of $\lambda_i$ is the number of times the root appears in the characteristic polynomial.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item \textbf{Definition}: Let $\lambda_i$ be an eigenvalue of a square matrix $\bm{A}$. 
    Then the \textbf{geometric multiplicity} of $\lambda_i$ is the number of linearly independent eigenvectors associated with $\lambda_i$. 
    In other words, it is the dimensionality of the eigenspace spanned by the eigenvectors associated with $\lambda_i$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item A specific eigenvalue’s geometric multiplicity must be at least one because every eigenvalue has at least one associated eigenvector. 
    An eigenvalue’s geometric multiplicity cannot exceed its algebraic multiplicity, but it may be lower.

    \item Geometrically, the eigenvector corresponding to a nonzero eigenvalue points in a direction that is stretched by the linear mapping.
    The eigenvalue is the factor by which it is stretched. 
    If the eigenvalue is negative, the direction of the stretching is flipped.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item \textbf{The Case of the Identity Matrix}: The identity matrix $\bm{I} \in \mathbb{R}^{n\times n}$ has characteristic polynomial $p_{\bm{I}} (\lambda ) = \det(\bm{I} -\lambda \bm{I}) = (1-\bm{\lambda }) ^n = 0$, which has only one eigenvalue $\lambda  = 1$ that occurs $n$ times. 
    Moreover, $\bm{Ix} = \lambda \bm{x} = 1\bm{x}$ holds for all vectors $\bm{x} \in \mathbb{R}^n\backslash \dCurlyBrac{0}$. 
    Because of this, the sole eigenspace $E_1$ of the identity matrix spans $n$ dimensions, and all $n$ standard basis vectors of $\mathbb{R}^n$ are eigenvectors of $\bm{I}$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item \textbf{Theorem}: The eigenvectors $\bm{x}_1, \cdots , \bm{x}_n$ of a matrix $\bm{A} \in \mathbb{R}^{n\times n}$ with $n$ distinct eigenvalues $\lambda _1, \cdots , \lambda _n$ are linearly independent.
    This theorem states that eigenvectors of a matrix with $n$ distinct eigenvalues form a basis of $\mathbb{R}^n$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item 
\end{enumerate}




\begin{lstlisting}[
    language=Python,
    caption=Eigenvalues \& Eigenvectors of a Matrix - numPy
]
import numpy as np

# Define a square matrix
A = np.random.randint(-10, 10, size=(3,3), dtype=int)
print(A)

# Compute eigenvalues and eigenvectors
# eigenvalues: 1D array of eigenvalues.
# eigenvectors: 2D array where each column is an eigenvector.
eigenvalues, eigenvectors = np.linalg.eig(A)
print(eigenvalues)
print(eigenvectors)
\end{lstlisting}



\subsubsection{Properties of eigenvalues \& eigenvectors}

\begin{enumerate}
    \item A matrix $\bm{A}$ and its transpose $\bm{A}^\top$ possess the same eigenvalues, but not necessarily the same eigenvectors.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Similar matrices possess the same eigenvalues.
    Therefore, a linear mapping $\Phi$ has eigenvalues that are independent of the choice of basis of its transformation matrix.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Symmetric, positive definite (SPD) matrices \textbf{always} have positive, real eigenvalues.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
\end{enumerate}




\subsection{Eigenspace ($E_\lambda $) \& Eigenspectrum}

\begin{enumerate}
    \item \textbf{Definition}: For $\bm{A} \in \mathbb{R}^{n\times n}$ , the set of all eigenvectors of $\bm{A}$ associated with an eigenvalue $\lambda $ spans a subspace of $\mathbb{R}^n$, which is called the \textbf{eigenspace} of $\bm{A}$ with respect to $\lambda $ and is denoted by $E_\lambda $.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item \textbf{Definition}: The set of all eigenvalues of $\bm{A}$ is called the \textbf{eigenspectrum}, or just spectrum, of $\bm{A}$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item If $\lambda $ is an eigenvalue of $\bm{A} \in \mathbb{R}^{n\times n}$ , then the corresponding eigenspace $E_\lambda $ is the solution space of the homogeneous system of linear equations $(\bm{A} - \lambda \bm{I})\bm{x} = 0$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
\end{enumerate}


\subsubsection{Properties of Eigenspace \& Eigenspectrum}

\begin{enumerate}
    \item The eigenspace $E_\lambda$  is the null space of $\bm{A} - \lambda \bm{I}$ since:
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \\
    .\hfill
    $
        \begin{aligned}
            \bm{Ax} = \lambda \bm{x}
            & \Longleftrightarrow \bm{Ax} - \lambda \bm{x} = 0 \\
            & \Longleftrightarrow (\bm{A} - \lambda \bm{I})\bm{x} = 0  
            & \Longleftrightarrow \bm{x} \in \ker(\bm{A} - \lambda \bm{I})
        \end{aligned}
    $
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
\end{enumerate}






