\chapter{Groups, Vector Spaces, Vector, etc}




\section{Groups}

\begin{enumerate}
    \item \textbf{Definition}: Consider a set $\mathcal{G}$ and an (inner) operation $\otimes : \mathcal{G} \times \mathcal{G} \to \mathcal{G}$ group defined on $G$. Then $G := (\mathcal{G}, \otimes)$ is called a group if the following hold:
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \begin{enumerate}
        \item Closure of $\mathcal{G}$ under $\otimes$: $\forall x, y \in \mathcal{G} : x \otimes y \in \mathcal{G}$
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item Associativity: $\forall x, y, z \in  \mathcal{G} : (x \otimes  y) \otimes  z = x \otimes  (y \otimes  z)$
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item Neutral element: $\exists e \in  \mathcal{G} \forall x \in  \mathcal{G} : x \otimes  e = x and e \otimes  x = x$
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item Inverse element: $\forall x \in  \mathcal{G} \exists y \in  \mathcal{G}$ : $x \otimes  y = e$ and $y \otimes  x = e$, where $e$ is the neutral element. We often write $x^{-1}$ to denote the inverse element of $x$.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \end{enumerate}

    \item The inverse element is defined with respect to the operation $\otimes$ and does not necessarily mean $\dfrac{1}{x}$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Group allows only inner operation $\otimes$, means the operands \textbf{must be} elements from $\mathcal{G}$.

    \item Examples:
    \begin{enumerate}
        \item $(\mathbb{N}_0, +)$ is \textbf{not} a group: Although $(\mathbb{N}_0, +)$ possesses a neutral element ($0$), the inverse elements are missing.
        \hfill $\mathbb{N}_0 := \mathbb{N} \cup \dCurlyBrac{0}$
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $(\mathbb{Z}, \cdot)$ is not a group: Although $(\mathbb{Z}, \cdot)$ contains a neutral element ($1$), the inverse elements for any $z \in \mathbb{Z}, z \neq \pm1$, are missing.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $(\mathbb{R}, \cdot)$ is not a group since $0$ does not possess an inverse element.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        
    \end{enumerate}
\end{enumerate}






\section{Abelian Group}

\begin{enumerate}
    \item \textbf{Definition}: A group $G = (\mathcal{G}, \otimes)$ is called Abelian group if $\forall x, y \in \mathcal{G} : x \otimes y = y \otimes x$ (commutative)
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Examples:
    \begin{enumerate}
        \item $(\mathbb{Z}, +)$ is an Abelian group
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $( \mathbb{R} \backslash \dCurlyBrac{0}, \cdot)$ is Abelian
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $(\mathbb{R}^n, +),(\mathbb{Z}^n, +), n \in \mathbb{N}$ are Abelian if + is defined component-wise:
        \\
        $
            (x_1, \cdots , x_n) + (y_1, \cdots , y_n) = (x_1 + y_1, \cdots , x_n + y_n)
        $
        \\
        Then, $(x_1, \cdots , x_n)^{-1} := (-x_1, \cdots , -x_n)$ is the inverse element and $e = (0, \cdots , 0)$ is the neutral element.

        \item $(\mathbb{R}^{m\times n} , +)$, the set of $m \times n$-matrices is Abelian  (with component-wise addition)

        
    \end{enumerate}
\end{enumerate}





\section{General Linear Group}

\begin{enumerate}
    \item \textbf{Definition}: The set of regular (invertible) matrices $A \in \mathbb{R}^{n\times n}$ is a group with respect to matrix multiplication and is called general linear group $GL(n, \mathbb{R})$. 
    
    \item However, since matrix multiplication is not commutative, the group is not Abelian.

    
\end{enumerate}






\section{Vector Space}

\begin{enumerate}
    \item \textbf{Definition}: A real-valued vector space $V = (\mathcal{V}, +, \cdot)$ is a set $\mathcal{V}$ with two operations:
    \begin{enumerate}
        \item[] $+ :  \mathcal{V} \times \mathcal{V} \to \mathcal{V}$

        \item[] $\cdot: \mathbb{R} \times \mathcal{V} \to \mathcal{V}$ 
    \end{enumerate}


    \item addition ($+$) is inner operation: both operands must be from $\mathcal{V}$

    \item multiplication by scalars ($\cdot$) is outer operation: one operand is from $\mathcal{V}$, another from $\mathbb{R}$

    \item The elements $x \in \mathcal{V}$ are called \textbf{vectors}.
\end{enumerate}


\subsection{Properties}

\begin{enumerate}
    \item $(\mathcal{V}, +)$ is an Abelian group

    \item Distributivity:
    \begin{enumerate}
        \item $\forall \lambda  \in  \mathbb{R}, x, y \in  \mathcal{V} : \lambda  \cdot  (x + y) = \lambda  \cdot  x + \lambda  \cdot  y$

        \item $\forall \lambda , \psi  \in  \mathbb{R}, x \in  \mathcal{V} : (\lambda  + \psi ) \cdot  x = \lambda  \cdot  x + \psi  \cdot  x$
    \end{enumerate}

    \item Associativity (outer operation): $\forall \lambda , \psi  \in  \mathbb{R}, x \in  \mathcal{V} : \lambda \cdot (\psi \cdot x) = (\lambda \psi )\cdot x$

    \item Neutral element with respect to the outer operation: $\forall x \in  \mathcal{V} : 1\cdot x = x$

    \item The neutral element of $(\mathcal{V}, +)$ is the zero vector $0 = [0, \cdots , 0]^\top$

    \item A “vector multiplication” $ab, a, b \in \mathbb{R}^n$, is \textbf{not defined}.
\end{enumerate}








\section{Vector Subspace/ linear subspace}


\begin{enumerate}
    \item \textbf{Definition}: Let $V = (\mathcal{V}, +, \cdot )$ be a vector space and $\mathcal{U} \subseteq \mathcal{V}, \mathcal{U} \neq \phi$. Then $U = (\mathcal{U}, +, \cdot )$ is called vector subspace of $V$ (or linear subspace) if $U$ is a vector space with the vector space operations $+$ and $\cdot$  restricted to $\mathcal{U} \times \mathcal{U}$ and $\mathbb{R} \times \mathcal{U}$. We write $U \subseteq V$ to denote a subspace $U$ of $V$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Intuitively, they are sets contained in the original vector space with the property that when we perform vector space operations on elements within this subspace, we will never leave it. 
    In this sense, they are “closed”.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item If $\mathcal{U} \subseteq \mathcal{V}$ and $V$ is a vector space, then $U$ naturally inherits many properties directly from $V$ because they hold for all $x \in \mathcal{V}$, and in particular for all $x \in \mathcal{U} \subseteq \mathcal{V}$. 
    This includes the Abelian group properties, the distributivity, the associativity and the neutral element.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item To determine whether $(\mathcal{U}, +, \cdot)$ is a subspace of V we still do need to show:
    \begin{enumerate}
        \item $\mathcal{U} \neq \phi$, in particular: $0 \in \mathcal{U}$
        \item Closure of $U$:
        \begin{enumerate}
            \item With respect to the outer operation: $\forall \lambda  \in  \mathbb{R} \forall x \in  \mathcal{U} : \lambda x \in  \mathcal{U}$.
            \item With respect to the inner operation: $\forall x, y \in  \mathcal{U} : x + y \in  \mathcal{U}$.
        \end{enumerate}
    \end{enumerate}
\end{enumerate}











\section{Vector}

\begin{enumerate}
    \item In general, vectors are special objects that can be added together and multiplied by scalars to produce another object of the same kind. From an abstract mathematical viewpoint, any object that satisfies these two properties can be considered a vector. 
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item By convention $(1, n)$-matrices are called rows and $(m, 1)$-matrices are called row columns. These special matrices are also called row/ column vectors.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    
\end{enumerate}


\subsection{Outer Product ($ab^\top$) }

\begin{enumerate}
    \item $\forall a,b \in \mathbb{R}^n, ab^\top \in \mathbb{R}^{n\times n}$
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    
\end{enumerate}



\subsection{Inner/scalar/dot product ($a^\top b$)}


\begin{enumerate}
    \item $\forall a,b \in \mathbb{R}^n, a^\top b \in \mathbb{R}$
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    
\end{enumerate}



\subsection{Types of vectors}

\begin{enumerate}
    \item $\mathbb{R}^n$ or $\mathbb{R}^{n\times 1}$ : column vectors: 
    $
        x = 
        \begin{bmatrix}
            x_1\\ \vdots \\ x_n
        \end{bmatrix}
    $
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item $\mathbb{R}^{1\times n}$ : row vectors: 
    $
        x^\top = \begin{bmatrix}x_1 & \cdots & x_n\end{bmatrix}
    $
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
\end{enumerate}













\section{Linear Combination}

\begin{enumerate}
    \item \textbf{Definition}: Consider a vector space $V$ and a finite number of vectors $x_1, \cdots , x_k \in V$ . Then, every $v \in V$ of the form:
    \\
    .\hfill
    $
        v = \lambda _1 x_1 + \cdots + \lambda _k x_k
        = \dsum_{i=1}^k \lambda _i x_i
        \in V
    $
    \hfill.
    \\
    with $\lambda _1, \cdots , \lambda _k \in \mathbb{R}$ is a linear combination of the vectors $x_1, \cdots , x_k$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item The $0$-vector can always be written as the linear combination of $k$ vectors $x_1, \cdots , x_k$ because $0 = \dsum ^k _{i=1} 0 x_i$ is always true.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    
\end{enumerate}



\section{Linear (In)dependence}

\begin{enumerate}
    \item \textbf{Definition}: Let us consider a vector space $V$ with $k \in \mathbb{N}$ and $x_1, \cdots , x_k \in V$ . If there is a non-trivial linear combination, such that $0 = \dsum ^k _{i=1} \lambda_i x_i$ with at least one $\lambda _i \neq 0$, the vectors  $x_1, \cdots , x_k$ are linearly dependent. 
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    
    \item If only the trivial solution exists, i.e., $\lambda _1 = \cdots = \lambda _k = 0$ the vectors $x_1, \cdots , x_k$ are linearly independent.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Intuitively, a set of linearly independent vectors consists of vectors that have no redundancy, i.e., if we remove any of those vectors from the set, we will lose something.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
\end{enumerate}


\subsection{Properties}
\begin{enumerate}
    \item $k$ vectors are either linearly dependent or linearly independent. There is no third option.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item If at least one of the vectors $x_1, \cdots , x_k$ is $0$ then they are linearly dependent. The same holds if two vectors are identical.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item The vectors $\dCurlyBrac{x_1, \cdots , x_k : x_i \neq 0, i = 1, \cdots , k}$, $k \geq 2$, are linearly dependent if and only if (at least) one of them is a linear combination of the others. In particular, if one vector is a multiple of another vector, i.e., $x_i = \lambda x_j , \lambda \in \mathbb{R}$ then the set $\dCurlyBrac{x_1, \cdots , x_k : x_i \neq 0, i = 1, \cdots , k}$ is linearly dependent.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item A practical way of checking whether vectors $x_1, \cdots , x_k \in V$ are linearly independent is to use Gaussian elimination: Write all vectors as columns of a matrix $A$ and perform Gaussian elimination until the matrix is in row echelon form (the reduced row-echelon form is unnecessary here):
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \begin{enumerate}
        \item The pivot columns indicate the vectors, which are linearly independent of the vectors on the left. Note that there is an ordering of vectors when the matrix is built.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item The non-pivot columns can be expressed as linear combinations of the pivot columns on their left.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \end{enumerate}
    All column vectors are linearly independent if and only if all columns are pivot columns. If there is at least one non-pivot column, the columns (and, therefore, the corresponding vectors) are linearly dependent.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Consider a vector space $V$ with $k$ linearly independent vectors $b_1, \cdots , b_k$ and $m$ linear combinations:
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \\
    .\hfill
    $
        x_1 = \dsum_{i=1}^k \lambda_{il} b_i,
        \hspace{1cm}
        \cdots,
        \hspace{1cm}
        x_m = \dsum_{i=1}^k \lambda_{im} b_i
    $
    \hfill.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \\
    \vspace{0.2cm}
    Defining $B = [b_1, \cdots , b_k]$ as the matrix whose columns are the linearly independent vectors $b_1, \cdots , b_k$, we can write:
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \\
    .\hfill
    $
        x_j = B\lambda_j, 
        \hspace{1cm}
        \lambda_j = \begin{bmatrix}\lambda_{1j} \\ \vdots \\ \lambda_{kj}\end{bmatrix},
        \hspace{1cm}
        j=1,\cdots,m
    $
    \hfill.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \\
    in a more compact form.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \begin{enumerate}
        \item to test whether $x_1, \cdots , x_m$ are linearly independent:
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
        \begin{enumerate}
            \item general approach of testing: $\dsum^m_{j=1} \psi_jx_j = 0$
            \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

            \item $
                    \dsum^m_{j=1} \psi_j x_j = 0
                    \hspace{1cm}
                    \Rightarrow \dsum^m_{j=1} \psi_j B \lambda_j = 0
                    \hspace{1cm}
                    \Rightarrow B \dsum^m_{j=1} \psi_j \lambda_j = 0
            $
            \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

            \item This means that $\dCurlyBrac{x_1, \cdots , x_m}$ are linearly independent if and only if the column vectors $\dCurlyBrac{\lambda_1, . . . , \lambda_m}$ are linearly independent.
            \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
        \end{enumerate}

        \item In a vector space $V$ , $m$ linear combinations of $k$ vectors $x_1, \cdots , x_k$ are linearly dependent if $m > k$.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \end{enumerate}
\end{enumerate}



\section{Generating Set}

\begin{enumerate}
    \item \textbf{Definition}: Consider a vector space $V = (\mathcal{V}, +, \cdot)$ and set of vectors $\mathcal{A} = \dCurlyBrac{x_1, \cdots , x_k} \subseteq \mathcal{V}$. 
    If every vector $v \in \mathcal{V}$ can be expressed as a linear combination of $x_1, \cdots , x_k$, $\mathcal{A}$ is called a generating set generating set of $V$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Generating sets are sets of vectors that span vector (sub)spaces, i.e., every vector can be represented as a linear combination of the vectors in the generating set.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
\end{enumerate}








\section{Span}

\begin{enumerate}
    \item \textbf{Definition}: Consider a vector space $V = (\mathcal{V}, +, \cdot)$ and set of vectors $\mathcal{A} = \dCurlyBrac{x_1, \cdots , x_k} \subseteq \mathcal{V}$. 
    The set of all linear combinations of vectors in $\mathcal{A}$ is span called the span of $\mathcal{A}$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item If $\mathcal{A}$ spans the vector space $V$ , we write $V = \text{span}[\mathcal{A}]$ or $V = \text{span}[x_1, \cdots , x_k]$.
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    
\end{enumerate}





\section{Basis}

\begin{enumerate}
    \item \textbf{Definition}: Consider a vector space $V = (\mathcal{V}, +, \cdot)$ and $\mathcal{A} \subseteq  \mathcal{V}$. 
    A generating set $\mathcal{A}$ of $V$ is called minimal if there exists no smaller set $\tilde{\mathcal{A}} \subsetneq \mathcal{A} \subseteq \mathcal{V}$ that spans $V$ . 
    Every linearly independent generating set of $V$ is minimal and is called a basis of $V$ .
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

    \item Let $V = (\mathcal{V}, +, \cdot)$ be a vector space and $\mathcal{B} \subseteq \mathcal{V}, \mathcal{B} \neq \phi$. Then, the following statements are equivalent:
    \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \begin{enumerate}
        \item $\mathcal{B}$ is a basis of $V$ .
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $\mathcal{B}$ is a minimal generating set.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item $\mathcal{B}$ is a maximal linearly independent set of vectors in $V$ , i.e., adding any other vector to this set will make it linearly dependent.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}

        \item Every vector $x \in V$ is a linear combination of vectors from $\mathcal{B}$, and every linear combination is unique, i.e., with
        \\
        $
            x 
            = \dsum_{i=1}^k \lambda_i b_i
            = \dsum_{i=1}^k \psi_i b_i
        $
        \\
        and $\lambda_i , \psi_i \in \mathbb{R}, b_i \in \mathcal{B}$ it follows that $\lambda_i = \psi_i , i = 1, \cdots , k$.
        \hfill \cite{mfml/book/mml/Deisenroth-Faisal-Ong}
    \end{enumerate}
\end{enumerate}




























