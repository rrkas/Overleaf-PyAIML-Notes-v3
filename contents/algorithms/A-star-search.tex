\section{A$^\ast$ Search}
\label{AI: Algorithms/A* Search}

.\hfill
$f(n) = g(n) + h(n)$
\hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

\ \\

\begin{enumerate}[itemsep=0.2cm]
    \item It evaluates nodes by combining $g(n)$, the cost to reach the node, and $h(n)$, the cost to get from the node to the goal ($f(n)$ = estimated cost of the cheapest solution through $n$)
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item A$^\ast$ selects a node $n$ for expansion, the optimal path to that node has been found
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item Because A$^\ast$ expands the frontier node of lowest $f$-cost, we can see that an A$^\ast$ search fans out from the start node, adding nodes in \textbf{concentric bands} of increasing $f$-cost.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item If $C^\ast$ is the cost of the optimal solution path, then we can say the following:
    \begin{enumerate}[itemsep=0.2cm]
        \item A$^\ast$ expands all nodes with $f(n) < C^\ast$
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item A$^\ast$ might then expand some of the nodes right on the “goal contour” (where $f(n) = C^\ast$) before selecting a goal node.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}

    \item if $h(n)$ is admissible, the algorithm can safely \textbf{ignore/ prune} this sub-tree while still guaranteeing optimality
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item  among optimal algorithms of this type - algorithms that extend search paths from the root and use the same heuristic information - A$^\ast$ is \textbf{optimally efficient} for any given consistent heuristic.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item best results follow the 3 assumptions:
    \begin{enumerate}
        \item Single goal state
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        
        \item Tree structure
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        
        \item Reversible actions
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}

    \item \textbf{Performance}:
    \begin{enumerate}[itemsep=0.2cm]
        \item the \textit{tree-search} version of A$^\ast$ is \textbf{optimal} if $h(n)$ is admissible, 
        while the \textit{graph-search} version is \textbf{optimal} if $h(n)$ is consistent
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{Completeness} requires that there be only finitely many nodes with cost less than or equal to $C^\ast$, a condition that is true if all step costs exceed some finite  and if $b$ is finite.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{time complexity}:
        \begin{enumerate}
            \item in maximum absolute error: $\mathcal{O}(b^\Delta)$
            \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
            
            \item constant step costs: $\mathcal{O}(b^{\Delta_rd})$ or $\mathcal{O}(b^{\epsilon d})$
            \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \end{enumerate}
    \end{enumerate}

    \item \textbf{Disadvantages}
    \begin{enumerate}
        \item for most problems, the number of states within the goal contour search space is still \textbf{exponential} in the length of the solution
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item Because it keeps all generated nodes in memory (as do all \textsc{Graph-Search} algorithms), A$^\ast$ usually runs out of space long before it runs out of time.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item A$^\ast$ is not practical for many large-scale problems. 
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}
\end{enumerate}


\vspace{0.5cm}

\begin{lstlisting}[
    language=Python,
    caption=Problem Solving Agent - A* search \cite{common/online/chatgpt}
]
def a_star_search(problem: Problem):
    start_node = Node(problem.initial_state, None, None, 0)

    if problem.goal_test(start_node.state):
        return solution(start_node)

    # Priority queue ordered by f(n) = g(n) + h(n)
    frontier = [(problem.heuristic(start_node.state), start_node)]
    heapq.heapify(frontier)

    explored = dict()  # {state: path_cost}

    while len(frontier)> 0:
        f, current = heapq.heappop(frontier)

        if problem.goal_test(current.state):
            return solution(current)

        # If this state has already been explored with a lower cost, skip
        if any(n.state == current.state for n in explored) and explored[current] <= current.path_cost:
            continue

        explored[current] = current.path_cost

        for action in problem.actions(current.state):
            child = child_node(problem, current, action)
            f_child = child.path_cost + problem.heuristic(child.state)

            # Check if child.state was already explored with a lower path_cost
            if (any(n.state == child.state for n in explored) or 
                explored[child] > child.path_cost):
                heapq.heappush(frontier, (f_child, child))

    return None  # No solution found

# A* Search using general best first search
a_star_search_alt = lambda problem: best_first_search(
    problem, 
    f=lambda n: n.path_cost + problem.heuristic(n.state)
)
\end{lstlisting}











