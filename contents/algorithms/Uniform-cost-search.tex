\section{Uniform-cost search (UCS) \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}}


\begin{enumerate}[itemsep=0.2cm]
    \item Instead of expanding the shallowest node (as in BFS), uniform-cost search expands the node $n$ with the \textbfit{lowest path cost} $g(n)$.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item \textbf{Performance}:
    \begin{enumerate}[itemsep=0.2cm]
        \item uniform-cost search is \textbf{optimal} in general. uniform-cost search expands nodes in order of their optimal path cost.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{Completeness is guaranteed} provided the cost of every step exceeds some small positive constant $\varepsilon$.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{Space Complexity}:
        \begin{enumerate}[itemsep=0.2cm]
            \item worst: $\mathcal{O}(b^{1 + \dfloor{C^\ast / \varepsilon}})$
            \hfill (can be much greater than $b^d$)
            \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

            \item When all step costs are equal: $\mathcal{O}(b^{\ d+1})$
            \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \end{enumerate}

        \item \textbf{Time Complexity}:
        \begin{enumerate}[itemsep=0.2cm]
            \item worst: $\mathcal{O}(b^{1 + \dfloor{C^\ast / \varepsilon}})$
            \hfill (can be much greater than $b^d$)
            \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

            \item When all step costs are equal: $\mathcal{O}(b^{\ d+1})$
            \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \end{enumerate}
    \end{enumerate}

    \item \textbf{Disadvantages}:
    \begin{enumerate}[itemsep=0.2cm]
        \item it will get stuck in an \textbf{infinite loop} if there is a path with an infinite sequence of \textit{zero-cost actions} - for example, a sequence of $NoOp$ actions.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}

    \item When all step costs are the same, uniform-cost search is similar to breadth-first search, except that the latter stops as soon as it generates a goal, whereas uniform-cost search examines all the nodes at the goalâ€™s depth to see if one has a lower cost; thus uniform-cost search does strictly more work by expanding nodes at depth $d$ unnecessarily.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
\end{enumerate}




\subsection{Implementation}

\begin{enumerate}
    \item  This is done by storing the frontier as a \textbf{priority queue} ordered by $g(n)$. 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item In addition to the ordering of the queue by path cost, there are two other significant differences from breadth-first search.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \begin{enumerate}
        \item  goal test is applied to a node when it is \textit{selected for expansion} rather than when it is first generated.
        The reason is that the first goal node that is \textit{generated} may be on a suboptimal path.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item a test is added in case a better path is found to a node currently on the frontier.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}

\end{enumerate}

\vspace{0.5cm}


\begin{algorithm}[H]
    \caption{\textsc{Uniform-Cost} search on a graph. \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}}

    \SetKwFunction{FUNCTION}{\textsc{Uniform-Cost-Search}}
    \SetKwProg{Fn}{function}{ returns \normalfont{a solution, or failure}}{end}
    \Fn{\FUNCTION{problem}}{
        $node \ \gets$ a node with \textsc{State} = $problem$.\textsc{Initial-State}, \textsc{Path-Cost} = $0$ \\
        $frontier \ \gets$ a \textbfit{priority queue} ordered by \textsc{Path-Cost}, with $node$ as the only element \\
        $explored \ \gets$ an empty set \\
        \ \\
        \While{}{
            \If{\textsc{Empty?}($frontier$)}{
                \Return failure
            }
            \ \\
            \Comment{chooses the lowest-cost node in $frontier$}
            $node \ \gets$ \textsc{Pop}($frontier$) \\ 
            \ \\
            \If{$problem$.\textsc{Goal-Test}($node$.\textsc{State})}{
                \Return \textsc{Solution}($node$)
            }
            \ \\
            add $node$.\textsc{State} to $explored$ \\
            \ \\
            \ForEach{$action$ \textbf{in} $problem$.\textsc{Actions}($node$.\textsc{State})}{
                $child \gets$ \textsc{Child-Node}($problem,\ node,\ action$) \\
                \If{\normalfont $child$.\textsc{State} is not in $explored$ or $frontier$}{
                    $frontier \gets$ \textsc{Insert}($child,\ frontier$)
                }
                \ElseIf{\normalfont $child$.\textsc{State} is in $frontier$ with higher \textsc{Path-Cost}}{
                    replace that $frontier$ node with $child$
                }
            }
        }
    }
\end{algorithm}


\begin{lstlisting}[
    language=Python,
    caption=Problem Solving Agent - Uniform cost search on a graph
]
import heapq

def uniform_cost_search(problem: Problem):
    node = Node(problem.initial_state, None, None, 0)

    if problem.goal_test(node.state):
        return solution(node)
    
    frontier = [(node.path_cost, node)]
    explored = set()

    heapq.heapify(frontier)

    while True:
        if len(frontier) == 0:
            return None
        
        path_cost, node = frontier.pop(0)

        if problem.goal_test(node.state):
            return solution(node)

        explored.add(node)
        for action in problem.actions(node.state):
            child = child_node(problem, node, action)

            if (not any([n.state == child.state for (path_cost, n) in frontier])
                and not any([n.state == child.state for n in explored])):
                frontier.append((child.path_cost, child))
                heapq.heapify(frontier)
            else:
                for idx, (path_cost, n) in enumerate(frontier):
                    if n.state == child.state and path_cost > child.path_cost:
                        frontier[idx] = (child.path_cost, child)
                        heapq.heapify(frontier)
\end{lstlisting}





