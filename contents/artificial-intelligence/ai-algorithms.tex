\chapter{AI: Algorithms}\label{AI: Algorithms}

\begin{customArrayStretch}{1.3}
\begin{table}[H]
\centering
\begin{tabular}{r c p{12cm}}

$V$ & set & set of vertices (nodes) of the graph \\

$E$ & set  & set of edges (links) of the graph \\

$b$ & $\in \mathbb{R}$ & \textbf{branching factor} or maximum number of successors of any node \\

$d$ & $\in \mathbb{R}$ & \textbf{depth} of the \textbf{shallowest goal} node (i.e., the number of steps along the path from the root) \\

$m$ & $\in \mathbb{R}$ & maximum length of any path in the state space \\

$\varepsilon$ & $\in \mathbb{R}$ & minimum step cost (small positive constant) \\

$C$ & $\in \mathbb{R}$ & cost of the solution \\

$C^\ast$ & $\in \mathbb{R}$ & cost of the optimal solution \\

$\ell$ & $\in \mathbb{R}$ & predetermined depth limit \\

$G_n$ & node & goal node closest to $n$ \\

\hline

$g(n)$ & $\in \mathbb{R}$ & Path Cost (The \textbf{actual cost} from the \textbfit{start node} to the current node $n$) (Eg: UCS) \\

$h(n)$ & $\in \mathbb{R}$ & Heuristic Estimate (The \textbf{estimated cost} from node $n$ to the \textbfit{goal}) (Eg: GBFS, A*) \\

$f(n)$ & $\in \mathbb{R}$ & Evaluation Function (The \textbf{total estimated cost} of the \textbfit{cheapest solution} through $n$) (Eg: A*) \\

$h^\ast(n)$ & $\in \mathbb{R}$ & actual cost of getting from the root to the goal \\

\hline

$\Delta$ & $\in \mathbb{R}$ & \textbf{absolute error}: $\Delta \equiv h^\ast - h$  \\

$\epsilon$ \textbf{OR} $\Delta_r$ & 
$\in \mathbb{R}$ & 
\textbf{relative error}: $\epsilon \equiv \Delta_r \equiv (h^\ast - h)/h^\ast$ \\


$b^{\Delta_r}$ \textbf{OR} $b^\epsilon$ &
$\in \mathbb{R}$ & 
effective branching factor \\




\end{tabular}
\caption*{Notations}
\end{table}
\end{customArrayStretch}


\begin{enumerate}[itemsep=0.2cm]
    \item \textbf{heuristic function}
    \begin{enumerate}[itemsep=0.2cm]
        \item $h(n)$ = estimated cost of the cheapest path from the state at node $n$ to a goal state
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item Heuristic functions are the most common form in which additional knowledge of the problem is imparted to the search algorithm. 
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        
        \item if $n$ is a goal node, then $h(n)=0$
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item it depends only on the \textbfit{state} at that node.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item the values of heuristic (eg: $h_{SLD}$) \textbf{may not} be computed from the problem description itself. Moreover, it takes a certain amount of experience to know that $h_{SLD}$ is correlated with actual road distances and is, therefore, a useful heuristic.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item With a good heuristic function, however, the complexity can be reduced substantially. 
        The amount of the reduction depends on the particular problem and on the quality of the heuristic.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{admissible heuristic}: An admissible heuristic is one that \textbf{never overestimates} the cost to reach the goal. 
        Admissible heuristics are by nature optimistic because they think the cost of solving the problem is less than it actually is.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{consistency/ monotonicity}: A heuristic $h(n)$ is consistent if, for every node $n$ and every successor $n^\prime$ of $n$ generated by any action $a$, the estimated cost of reaching the goal from $n$ is no greater than the step cost of getting to $n^\prime$ plus the estimated cost of reaching the goal from $n$:
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \\
        .\hfill $h(n) \leq c(n,\ a,\ n^\prime) + h(n^\prime)$
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \\
        \textbf{every} consistent heuristic is also admissible
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item Consistency is a stricter requirement than admissibility, but one has to work quite hard to concoct heuristics that are admissible but not consistent.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item if $h(n)$ is consistent, then the values of $f(n)$ along any path are non-decreasing
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item For almost all heuristics in practical use, the absolute error is at least proportional to the path cost $h^\ast$, so $\epsilon$ is constant or growing and the time complexity is exponential in $d$.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}

    \item \textbf{evaluation function}:
    \begin{enumerate}[itemsep=0.2cm]
        \item The evaluation function $f$ is construed/ interpreted as a cost estimate, so the node with the lowest evaluation is expanded first.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        
        \item The choice of $f$ determines the search strategy.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item $f(n) = g(n)$ or $h(n)$ or $g(n)+h(n)$ or something else depending on the algorithm

        \item The fact that $f$-costs are \textit{non-decreasing} along any path also means that we can draw \textbf{contours} in the state space, just like the contours in a topographic map. 
        With more accurate heuristics, the bands will stretch toward the goal state and become more narrowly focused around the optimal path.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}
\end{enumerate}





\input{contents/algorithms/Breadth-first-search}
\input{contents/algorithms/Uniform-cost-search}
\input{contents/algorithms/Depth-first-search}
\input{contents/algorithms/Backtracking-Search}
\input{contents/algorithms/Depth-limited-search}
\input{contents/algorithms/Iterative-Deepening-Search}
\input{contents/algorithms/Iterative-Lengthening-Search}
\input{contents/algorithms/Bidirectional-search}


\input{contents/algorithms/Best-first-search}
\input{contents/algorithms/Greedy-best-first-search}
\input{contents/algorithms/A-star-search}


\clearpage
\input{contents/algorithms/__summary__}

