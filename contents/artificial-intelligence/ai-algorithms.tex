\chapter{AI: Algorithms}\label{AI: Algorithms}

\begin{customArrayStretch}{1.5}
\begin{longtable}{r c p{12cm}}
$V$ & 
set & 
set of vertices (nodes) of the graph \\ \hline

$E$ & 
set & 
set of edges (links) of the graph \\ \hline

$b$ & 
$\in \mathbb{R}$ & 
\textbf{branching factor} or maximum number of successors of any node \\ \hline

$d$ & 
$\in \mathbb{R}$ & 
\textbf{depth} of the \textbf{shallowest goal} node (i.e., the number of steps along the path from the root) \\ \hline

$m$ & 
$\in \mathbb{R}$ & 
maximum length of any path in the state space \\ \hline

$\varepsilon$ & $\in \mathbb{R}$ & minimum step cost (small positive constant) \\ \hline

$C$ & $\in \mathbb{R}$ & cost of the solution \\ \hline

$C^\ast$ & $\in \mathbb{R}$ & cost of the optimal solution \\ \hline

$\ell$ & $\in \mathbb{R}$ & predetermined depth limit \\ \hline

$G_n$ & node & goal node closest to $n$ \\ \hline

$M$ & $\in \mathbb{R}$ & memory bound \\ \hline

$N$ & $\in \mathbb{R}$ & total number of nodes generated \\ \hline

$k$ & $\in \mathbb{R}$ & \tableenumerate{
    \item number of restarts (for \fullref{AI: Algorithms/Random-restart hill climbing search})
    \item number of beams (for \fullref{AI: Algorithms/Local beam search})
} \\ \hline

$p$ & 
$\in \mathbb{R}$ & 
population size (for \fullref{AI: Algorithms/Genetic algorithm (GA)}) \\ \hline

$f$ & 
$\in \mathbb{R}$ & 
time to evaluate the fitness function (for \fullref{AI: Algorithms/Genetic algorithm (GA)}) \\ \hline






\hhline{===}





$g(n)$ & 
$\in \mathbb{R}$ & 
Path Cost (The \textbf{actual cost} from the \textbfit{start node} to the current node $n$) (Eg: UCS) \\ \hline

$h(n)$ & 
$\in \mathbb{R}$ & 
Heuristic Estimate (The \textbf{estimated cost} from node $n$ to the \textbfit{goal}) (Eg: GBFS, A*) \\ \hline

$f(n)$ & 
$\in \mathbb{R}$ & 
Evaluation Function (The \textbf{total estimated cost} of the \textbfit{cheapest solution} through $n$) (Eg: A*) \\ \hline

$h^\ast(n)$ & 
$\in \mathbb{R}$ & 
actual cost of getting from the root to the goal \\ \hline




\hhline{===}




$\Delta$ & 
$\in \mathbb{R}$ & 
\textbf{absolute error}: $\Delta \equiv h^\ast - h$  \\ \hline

$\epsilon$ \textbf{OR} $\Delta_r$ & 
$\in \mathbb{R}$ & 
\textbf{relative error}: $\epsilon \equiv \Delta_r \equiv (h^\ast - h)/h^\ast$ \\ \hline


$b^{\Delta_r}$ \textbf{OR} $b^\epsilon$ \textbf{OR} $b^\ast$ &
$\in \mathbb{R}$ & 
effective branching factor \\ \hline






\end{longtable}
\end{customArrayStretch}


\begin{enumerate}
    \item \textbf{heuristic function}
    \begin{enumerate}
        \item $h(n)$ = estimated cost of the cheapest path from the state at node $n$ to a goal state
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item Heuristic functions are the most common form in which additional knowledge of the problem is imparted to the search algorithm. 
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        
        \item if $n$ is a goal node, then $h(n)=0$
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item it depends only on the \textbfit{state} at that node.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item the values of heuristic (eg: $h_{SLD}$) \textbf{may not} be computed from the problem description itself. Moreover, it takes a certain amount of experience to know that $h_{SLD}$ is correlated with actual road distances and is, therefore, a useful heuristic.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item With a good heuristic function, however, the complexity can be reduced substantially. 
        The amount of the reduction depends on the particular problem and on the quality of the heuristic.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{admissible heuristic}: An admissible heuristic is one that \textbf{never overestimates} the cost to reach the goal. 
        Admissible heuristics are by nature optimistic because they think the cost of solving the problem is less than it actually is.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{consistency/ monotonicity}: A heuristic $h(n)$ is consistent if, for every node $n$ and every successor $n^\prime$ of $n$ generated by any action $a$, the estimated cost of reaching the goal from $n$ is no greater than the step cost of getting to $n^\prime$ plus the estimated cost of reaching the goal from $n$:
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \\
        .\hfill $h(n) \leq c(n,\ a,\ n^\prime) + h(n^\prime)$
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \\
        \textbf{every} consistent heuristic is also admissible
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item Consistency is a stricter requirement than admissibility, but one has to work quite hard to concoct heuristics that are admissible but not consistent.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item if $h(n)$ is consistent, then the values of $f(n)$ along any path are non-decreasing
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item For almost all heuristics in practical use, the absolute error is at least proportional to the path cost $h^\ast$, so $\epsilon$ is constant or growing and the time complexity is exponential in $d$.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item When the state space has many goal states - particularly \textbf{near-optimal goal} states - the search process can be led astray from the optimal path and there is an extra cost proportional to the number of goals whose cost is within a factor  of the optimal cost.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item experimental measurements of b$^\ast$ on a small set of problems can provide a good guide to the heuristic’s overall usefulness. 
        A well-designed heuristic would have a value of b$^\ast$ close to $1$, allowing fairly large problems to be solved at reasonable computational cost.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item \textbf{Dominating heuristic}: if for any node $n$, $h_2(n) \geq h_1(n)$, $h_2$ \textbf{dominates} $h_1$.
        Domination translates directly into efficiency: algorithm using $h_2$ will \textbf{never} expand more nodes than same algorithm using $h_1$ 
        (except possibly for some nodes with $f(n) = C^\ast$).
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \\
        For A$^\ast$ search, every node with $f(n) < C^\ast$ will surely be expanded.
        This is the same as saying that every node with $h(n) < C^\ast - g(n)$ will surely be expanded.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item One problem with generating new heuristic functions is that one often fails to get a single “clearly best” heuristic. 
        If a collection of admissible heuristics $h_1, \cdots, h_m$ is available for a problem and none of them dominates any of the others, we need not make a choice:
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \\
        .\hfill
        $h(n) = \max\dCurlyBrac{h_1(n),\cdots,h_m(n)}$
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        \\
        This \textbf{composite heuristic} uses whichever function is most accurate on the node in question.
        Because the component heuristics are admissible, $h$ is admissible; it is also easy to prove that $h$ is consistent. 
        Furthermore, $h$ dominates all of its component heuristics.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item Note that a perfect heuristic can be obtained simply by allowing h to run a full breadth-first search “on the sly”. 
        Thus, there is a tradeoff between accuracy and computation time for heuristic functions.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item Admissible heuristics can also be derived from the solution cost of a \textbf{subproblem} of a given problem.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item The idea behind \textbf{pattern databases} is to store these exact solution costs for every possible subproblem instance.
        We compute an admissible heuristic $h_{DB}$ for each complete state encountered during a search simply by looking up the corresponding subproblem configuration in the database. 
        The database itself is constructed by searching back from the goal and recording the cost of each new pattern encountered; the expense of this search is amortized over many subsequent problem instances.
        Each database yields an admissible heuristic, and these heuristics can be combined by taking the maximum value.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item 
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}

    \item \textbf{evaluation function}:
    \begin{enumerate}
        \item The evaluation function $f$ is construed/ interpreted as a cost estimate, so the node with the lowest evaluation is expanded first.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
        
        \item The choice of $f$ determines the search strategy.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item $f(n) = g(n)$ or $h(n)$ or $g(n)+h(n)$ or something else depending on the algorithm

        \item The fact that $f$-costs are \textit{non-decreasing} along any path also means that we can draw \textbf{contours} in the state space, just like the contours in a topographic map. 
        With more accurate heuristics, the bands will stretch toward the goal state and become more narrowly focused around the optimal path.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item There can be exponentially many states with $f(n) < C^\ast$ even if the absolute error is bounded by a constant.
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        
    \end{enumerate}

    \item memory limitations can make a problem intractable from the point of view of computation time
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item The effective branching factor can vary across problem instances, but usually it is fairly constant for sufficiently hard problems.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
\end{enumerate}


\vspace{1cm}
{\centering\fontsize{25}{25}\selectfont\bfseries Classical Search Algorithms \par}
\vspace{0.5cm}

\begin{enumerate}
    \item \textbf{category of problems}: observable, deterministic, known environments where the solution is a sequence of actions
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item These search algorithms are designed to explore search spaces \textbf{systematically}. 
    This systematicity is achieved by keeping one or more paths in memory and by recording which alternatives have been explored at each point along the path. 
    When a goal is found, the path to that goal also constitutes a solution to the problem. 
    In many problems, however, the path to the goal is irrelevant.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
\end{enumerate}
\vspace{0.5cm}


\clearpage
{\centering\fontsize{22}{22}\selectfont\bfseries Uninformed Search/ Blind Search \par}
\vspace{0.5cm}



\input{contents/algorithms/Breadth-first-search}
\input{contents/algorithms/Uniform-cost-search}
\input{contents/algorithms/Depth-first-search}
\input{contents/algorithms/Backtracking-Search}
\input{contents/algorithms/Depth-limited-search}
\input{contents/algorithms/Iterative-Deepening-Search}
\input{contents/algorithms/Iterative-Lengthening-Search}
\input{contents/algorithms/Bidirectional-search}


\clearpage
{\centering\fontsize{22}{22}\selectfont\bfseries Informed Search/ Heuristic Search \par}
\vspace{0.5cm}

\input{contents/algorithms/Best-first-search}
\input{contents/algorithms/Greedy-best-first-search}
\input{contents/algorithms/A-star-search}
\input{contents/algorithms/Iterative-Deepening-A-star-search}
\input{contents/algorithms/Recursive-best-first-search}
\input{contents/algorithms/Memory-Bounded-A-star-Search}
\input{contents/algorithms/Simplified-Memory-Bounded-A-star-Search}


\clearpage
{\centering\fontsize{22}{22}\selectfont\bfseries Local Search \par}
\vspace{0.5cm}

\input{contents/algorithms/Greedy-Hill-Climbing-Search}
\input{contents/algorithms/Stochastic-hill-climbing-search}
\input{contents/algorithms/First-choice-hill-climbing-search}
\input{contents/algorithms/Random-restart-hill-climbing-search}
\input{contents/algorithms/Simulated-annealing-search}
\input{contents/algorithms/Local-beam-search}
\input{contents/algorithms/stochastic-beam-search}
\input{contents/algorithms/Genetic-algorithm}













\clearpage
\input{contents/algorithms/__summary__}

