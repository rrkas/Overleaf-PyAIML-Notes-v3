\chapter{AI: Searching Solutions}


\begin{enumerate}[itemsep=0.2cm]
    \item A solution is an action sequence, so search algorithms work by considering various possible action sequences.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item The possible action sequences starting at the initial state form a \textbf{search tree} with the initial state at the root; the branches are actions and the \textbf{nodes} correspond to states in the state space of the problem. 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item We consider taking various actions by \textbf{expanding} the current state; that is, applying each legal action to the current state, thereby \textbf{generating} a new set of states.
    The process of expanding nodes on the frontier continues until either a solution is found or there are no more states to expand.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item \textbf{leaf node}: a node with \textbf{no} children in the tree. 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item \textbf{frontier/ open list}: set of all leaf nodes available for expansion at any given point 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item Search algorithms all share this basic structure; they vary primarily according to how they choose which state to expand next - the so-called \textbf{search strategy}.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item Considering \textbf{loopy paths} means that the complete search tree is \textbf{infinite} because there is no limit to how often one can traverse a loop. 
    loops can cause certain algorithms to fail, making otherwise solvable problems \textbf{unsolvable}.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item In some cases, \textbf{redundant paths} are \textit{unavoidable}. This includes all problems where the actions are reversible, such as route-finding problems and sliding-block puzzles.
    Following redundant paths can cause a tractable problem to become \textbf{intractable}. This is true even for algorithms that know how to avoid infinite loops.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
\end{enumerate}



\section{Designing Search Node}

\begin{figure}[H]
    \centering
    \includegraphics[
        width=0.5\linewidth,
        height=4cm,
        keepaspectratio,
    ]{images/artificial-intelligence/searching/search-node-sample.png}
    \caption*{Nodes are the data structures from which the search tree is constructed. Each has a parent, a state, and various bookkeeping fields. Arrows point from child to parent. \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}}
\end{figure}


\noindent
For each \textsc{Node} $n$ of the tree, we have a structure that contains four components:
\begin{enumerate}[itemsep=0.2cm]
    \item $n$.\textsc{State}: the state in the state space to which the node corresponds
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item $n$.\textsc{Parent}: the node in the search tree that generated this node
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item $n$.\textsc{Action}: the action that was applied to the parent to generate the node
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item $n$.\textsc{Path-Cost}: the cost, traditionally denoted by $g(n)$, of the path from the initial state to the node, as indicated by the parent pointers
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
\end{enumerate}


\vspace{0.3cm}


\textbf{Note}:
\begin{enumerate}
    \item A node is a bookkeeping data structure used to represent the search tree. 
    A state corresponds to a configuration of the world. 
    Thus, nodes are on particular paths, as defined by \textsc{Parent} pointers, whereas states are not. 
    Furthermore, two different nodes can contain the same world state if that state is generated via two different search paths.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item The \textsc{Parent} pointers string the nodes together into a tree structure. These pointers also allow the solution path to be extracted when a goal node is found.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item \textsc{Solution} function is used to return the sequence of actions obtained by following parent pointers back to the root.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
\end{enumerate}

\vspace{0.5cm}

\begin{lstlisting}[
    language=Python,
    caption=Problem Solving Agent - Search Node
]
class Node:
    def __init__(self, state, parent, action, path_cost):
        # the state in the state space to which the node corresponds
        self.state = state

        # the node in the search tree that generated this node
        self.parent = parent

        # the action that was applied to the parent to generate the node
        self.action = action

        """
            the cost, traditionally denoted by g(n), of the path
            from the initial state to the node, as indicated
            by the parent pointers
        """
        self.path_cost = path_cost
    
    def __lt__(self, __o):
        return self.path_cost < __o.path_cost

    def __str__(self):
        return (
            "<Node "
            + f"state: {self.state} "
            + f"parent: {self.parent} "
            + f"action: {self.action} "
            + f"path_cost: {self.path_cost} "
            + ">"
        )
    
    def __repr__(self) -> str:
        return str(self)
\end{lstlisting}



\begin{lstlisting}[
    language=Python,
    caption=Problem Solving Agent - solution
]
def solution(node: Node):
    path = []

    while node.parent is not None:
        path.insert(0, node.action)
        node = node.parent
    
    return path
\end{lstlisting}






\section{General Algorithms \& Implementations}

\subsection{Child-node}

\vspace{0.2cm}

\begin{algorithm}[H]
    \caption{The function \textsc{Child-Node} takes a parent node and an action and returns the resulting child node \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}}

    \SetKwFunction{FUNCTION}{\textsc{Child-Node}}
    \SetKwProg{Fn}{function}{ returns \normalfont{a \textsc{Node}}}{end}
    \Fn{\FUNCTION{problem}}{
        \Return a node with\\
            \hspace{1cm} \textsc{State} = $problem$.\textsc{Result}($parent$.\textsc{State}, $action$),\\
            \hspace{1cm} \textsc{Parent} = $parent$,\\
            \hspace{1cm} \textsc{Action} = $action$, \\
            \hspace{1cm} \textsc{Path-Cost} = $parent$.\textsc{Path-Cost} + 
                $problem$.\textsc{Step-Cost}($parent$.\textsc{State}, $action$)
    }
\end{algorithm}


\begin{lstlisting}[
    language=Python,
    caption=Problem Solving Agents - child\_node
]
def child_node(problem: Problem, parent: Node, action):
    new_state = problem.result(parent.state, action)

    return Node(
        state=new_state,
        parent=parent,
        action=action,
        path_cost=(parent.path_cost
            + problem.step_cost(parent.state, action, new_state))
    )
\end{lstlisting}



\subsection{Tree Search}
\vspace{0.2cm}

\begin{algorithm}[H]
    \caption{An informal description of the general tree-search algorithm. \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}}

    \SetKwFunction{FUNCTION}{\textsc{Tree-Search}}
    \SetKwProg{Fn}{function}{ returns \normalfont{a solution, or failure}}{end}
    \Fn{\FUNCTION{problem}}{
        initialize the frontier using the initial state of problem\\
        \ \\
        \While{}{
            \If{the frontier is empty}{
                \Return failure
            }
            choose a leaf node and remove it from the frontier\\
            \If{the node contains a goal state}{
                \Return the corresponding solution
            }
            expand the chosen node, adding the resulting nodes to the frontier
        }
    }
\end{algorithm}


\begin{lstlisting}[
    language=Python,
    caption=Problem Solving Agents - tree\_search
]
def tree_search(problem: Problem):
    frontier = [Node(problem.initial_state, None, None, 0)]

    while True:
        if len(frontier) == 0:
            return None
        
        node: Node = frontier.pop()

        if problem.goal_test(node.state):
            return solution(node)
        
        for action in problem.actions(node.state):
            new_state = problem.result(node.state, action)
            path_cost = (node.path_cost 
                + problem.step_cost(node.state, action, new_state))
            new_node = Node(new_state, node, action, path_cost)
            frontier.append(new_node)
\end{lstlisting}




\subsection{Graph search}
\vspace{0.2cm}

\begin{algorithm}[H]
    \caption{An informal description of the general graph-search algorithm. The parts of \textsc{Graph-Search} marked in bold italic are the additions needed to handle repeated states. \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}}

    \SetKwFunction{FUNCTION}{\textsc{Graph-Search}}
    \SetKwProg{Fn}{function}{ returns \normalfont{a solution, or failure}}{end}
    \Fn{\FUNCTION{problem}}{
        initialize the frontier using the initial state of problem \\
        \textbfit{initialize the explored set to be empty} \\
        \ \\
        \While{}{
            \If{the frontier is empty}{
                \Return failure
            }
            choose a leaf node and remove it from the frontier\\
            \If{the node contains a goal state}{
                \Return the corresponding solution
            }
            \textbfit{add the node to the explored set} \\
            \If{\bfseries chosen node not in the frontier or explored set}{
                expand the chosen node, adding the resulting nodes to the frontier
            }
        }
    }
\end{algorithm}

\begin{lstlisting}[
    language=Python,
    caption=Problem Solving Agents - graph\_search
]
def graph_search(problem: Problem):
    frontier = [Node(problem.initial_state, None, None, 0)]
    explored = set()

    while True:
        if len(frontier) == 0:
            return None

        node: Node = frontier.pop()

        if problem.goal_test(node.state):
            return solution(node)

        explored.add(node)

        for action in problem.actions(node.state):
            new_state = problem.result(node.state, action)
            path_cost = (node.path_cost
                + problem.step_cost(node.state, action, new_state))
            new_node = Node(new_state, node, action, path_cost)
            
            if new_node not in frontier and new_node not in explored:
                frontier.append(new_node)
\end{lstlisting}


\begin{enumerate}
    \item \textbf{explored set/ closed list}: remembers every expanded node
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item Newly generated nodes that match previously generated nodes - ones in the explored set or the frontier - can be discarded instead of being added to the frontier. 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item the search tree constructed by the \textsc{Graph-Search} algorithm contains \textbf{at most one copy} of each state, so we can think of it as growing a tree directly on the state-space graph.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item The explored set can be implemented with a \textbf{hash table} to allow efficient checking for repeated states.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    
\end{enumerate}



\section{Search Strategies/ Search Algorithms}

\subsection{Uninformed Search/ Blind Search}

\begin{enumerate}[itemsep=0.2cm]
    \item strategies have \textbf{no} additional information about states beyond that provided in the problem definition.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item All they can do is generate successors and distinguish a goal state from a non-goal state. All search strategies are distinguished by the order in which nodes are expanded. 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
\end{enumerate}


\vspace{0.3cm}
\textbf{SEE}:
\begin{enumerate}
    \item[] \fullref{AI: Algorithms/Breadth-first search (BFS)}
    \item[] \fullref{AI: Algorithms/Uniform-cost search (UCS)}
    \item[] \fullref{AI: Algorithms/Depth-first search (DFS)}
    \item[] \fullref{AI: Algorithms/Backtracking Search}
    \item[] \fullref{AI: Algorithms/Depth-limited search (DLS)}
    \item[] \fullref{AI: Algorithms/Iterative Deepening Search (IDS)}
    \item[] \fullref{AI: Algorithms/Iterative Lengthening Search (ILS)}
    \item[] \fullref{AI: Algorithms/Bidirectional search}
\end{enumerate}




\subsection{Informed Search/ Heuristic Search}

\begin{enumerate}[itemsep=0.2cm]
    \item Strategies that know whether one non-goal state is “\textit{more promising}” than another 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item uses problem-specific knowledge beyond the definition of the problem itself - can find solutions more efficiently than can an uninformed strategy.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    
\end{enumerate}


\vspace{0.3cm}
\textbf{SEE}:
\begin{enumerate}
    \item[] \fullref{AI: Algorithms/Best-first search (BestFS)}
    \item[] \fullref{AI: Algorithms/Greedy best-first search (GBFS)}
    \item[] \fullref{AI: Algorithms/A* Search}
    \item[] \fullref{AI: Algorithms/Iterative-Deepening A* search}
    \item[] \fullref{AI: Algorithms/Recursive best-first search (RBFS)}
    \item[] \fullref{AI: Algorithms/Memory-Bounded A* (MA*) Search}
    \item[] \fullref{AI: Algorithms/Simplified Memory-Bounded A* (SMA*) Search}
\end{enumerate}


\subsection{Local Search}

\begin{figure}[H]
    \centering
    \includegraphics[
        width=\linewidth,
        height=6cm,
        keepaspectratio,
    ]{images/artificial-intelligence/searching/state-space-landscape--objective-function.png}
    \caption*{
        A one-dimensional \textbf{state-space landscape} in which elevation corresponds to the objective function. The aim is to find the global maximum.
        \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    }
\end{figure}

\begin{enumerate}[itemsep=0.2cm]
    \item[] {\fontsize{18}{18} \textbf{State-space landscape}}:
    
    \item A landscape has both “location” (defined by the state) and “elevation” (defined by the value of the heuristic cost function or objective function).
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item if elevation corresponds to cost, then the aim is to find the lowest valley (\textbf{global minimum})
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item if elevation corresponds to an objective function, then the aim is to find the highest peak (\textbf{global maximum})
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item These can convert from one to the other just by inserting a minus sign.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item[] {\fontsize{18}{18} \textbf{Local Search}}:

    \item evaluates and modifies one or more current states rather than systematically exploring paths from an initial state.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item These algorithms are suitable for problems in which all that matters is the solution state, not the path cost to reach it.
    these do not worry about paths at all.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item The family of local search algorithms includes methods inspired by statistical physics (simulated annealing) and evolutionary biology (genetic algorithms).
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item Local search algorithms operate using a \textbf{single current node} (rather than multiple paths) and generally move only to neighbors of that node.
    Typically, the paths followed by the search are \textbf{not retained}.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item local search algorithms are useful for solving \textbf{pure optimization problems}, in which the aim is to find the best state according to an \textbf{objective function}.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item Many optimization problems do not fit the “standard” search models. 
    \textbf{For example}: nature provides an objective function—reproductive fitness—that Darwinian evolution could be seen as attempting to optimize, but there is no “goal test” and no “path cost” for this problem.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item  Local search algorithms explore this state-space landscape. 
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item A complete local search algorithm always finds a goal if one exists.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    
    \item An optimal algorithm always finds a global minimum/ maximum.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    \item \textbf{Advantages}: 
    \begin{enumerate}[itemsep=0.2cm]
        \item they use very little memory—usually a constant amount
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

        \item they can often find reasonable solutions in large or infinite (continuous) state spaces for which systematic algorithms are unsuitable
        \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}
    \end{enumerate}
\end{enumerate}





\subsection{Online Search}

\begin{enumerate}[itemsep=0.2cm]
    \item agent is faced with a state space that is initially unknown and must be explored.
    \hfill \cite{ai/book/Artificial-Intelligence-A-Modern-Approach/Russell-Norvig}

    
    
\end{enumerate}














